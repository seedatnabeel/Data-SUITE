{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c63c701",
   "metadata": {},
   "source": [
    "# RUN SYNTHETIC DATA EXPERIMENTS & LOG TO WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"ADD YOUR API KEY HERE\"\n",
    "project_name = \"data_suite_synthetic\"\n",
    "wandb_entity = \"ADD YOUR ENTITY HERE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c38851",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import wandb\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from src.data.data_loader import load_synthetic_data\n",
    "from src.models.benchmarks import comparison_methods\n",
    "from src.models.conformal import conformal_class\n",
    "from src.models.copula import fit_sample_copula\n",
    "from src.models.representation import compute_representation\n",
    "from src.utils.data_utils import covariance_comparison, get_suspect_features\n",
    "from src.utils.helpers import inlier_outlier_dicts, sort_cis_synth\n",
    "from src.utils.uncertainty_metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0fd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5164c28",
   "metadata": {},
   "source": [
    "## RUN SYNTHETIC EXPERIMENT WITH DIFFERENT PARAMTERIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80c618",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "props = [0.1, 0.25, 0.5, 0.75]\n",
    "dists = [\"normal\", \"beta\", \"gamma\", \"weibull\"]\n",
    "noise_vars = [1, 2, 5, 10]\n",
    "copula_count_samples = [1000]\n",
    "import traceback\n",
    "\n",
    "n_runs=20 # this can be reduced to 10 too\n",
    "\n",
    "for i in range(n_runs):\n",
    "    for prop in props:\n",
    "        for dist in dists:\n",
    "            for noise_variance in noise_vars:\n",
    "                for copula_n_samples in copula_count_samples:\n",
    "\n",
    "                    try:\n",
    "                        n_synthetic = 1000\n",
    "                        train_prop = 1\n",
    "                        rep_type = \"pca\"\n",
    "\n",
    "                        wandb_dict = {}\n",
    "                        wandb_dict[\"prop\"] = prop\n",
    "                        wandb_dict[\"dist\"] = dist\n",
    "                        wandb_dict[\"copula_n_samples\"] = copula_n_samples\n",
    "                        wandb_dict[\"n_synthetic\"] = n_synthetic\n",
    "                        wandb_dict[\"train_prop\"] = train_prop\n",
    "                        wandb_dict[\"noise_variance\"] = noise_variance\n",
    "                        wandb_dict[\"rep_type\"] = rep_type\n",
    "\n",
    "                        #\n",
    "                        logging.info(\n",
    "                            f\"Starting experiment {prop}, {dist}, {noise_variance}, {copula_n_samples}\"\n",
    "                        )\n",
    "                        \n",
    "                        run = wandb.init(\n",
    "                            project=project_name,\n",
    "                            entity=wandb_entity,\n",
    "                        )\n",
    "\n",
    "                        logging.info(\"Loading synthetic data...\")\n",
    "                        (\n",
    "                            train,\n",
    "                            test,\n",
    "                            orig_test,\n",
    "                            noise_bool,\n",
    "                            noise_matrix,\n",
    "                            noise_idx,\n",
    "                        ) = load_synthetic_data(\n",
    "                            n_synthetic=n_synthetic,\n",
    "                            mean=0,\n",
    "                            noise_variance=noise_variance,\n",
    "                            dim=\"small\",\n",
    "                            prop=prop,\n",
    "                            dist=dist,\n",
    "                        )\n",
    "\n",
    "                        cov_suspects = covariance_comparison(\n",
    "                            clean_array=train, noisy_array=test\n",
    "                        )\n",
    "                        ks_suspect = get_suspect_features(\n",
    "                            clean_corpus=train, test_dataset=test, alpha=0.1\n",
    "                        )\n",
    "                        suspect_features = np.unique(\n",
    "                            np.append(cov_suspects, ks_suspect)\n",
    "                        )\n",
    "                        suspect_features = np.unique(np.append(suspect_features, [0]))\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # STEP 1: COPULA\n",
    "                        #\n",
    "                        ##############################################################\n",
    "                        logging.info(\"Fitting Copula\")\n",
    "\n",
    "                        copula_samples = fit_sample_copula(\n",
    "                            clean_corpus=train,\n",
    "                            copula=\"vine\",\n",
    "                            copula_n_samples=copula_n_samples,\n",
    "                        )\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # STEP 2: REPRESENTER\n",
    "                        #\n",
    "                        ##############################################################\n",
    "\n",
    "                        logging.info(\"Running representer...\")\n",
    "\n",
    "                        rep_dim = int(np.ceil(train.shape[1] / 2))\n",
    "                        pcs_train, pcs_test, pcs_copula = compute_representation(\n",
    "                            train,\n",
    "                            test,\n",
    "                            copula_samples,\n",
    "                            n_components=rep_dim,\n",
    "                            rep_type=rep_type,\n",
    "                        )\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # STEP 3: CONFORMAL PREDICTOR\n",
    "                        #\n",
    "                        ##############################################################\n",
    "                        logging.info(\"Running conformal predictor...\")\n",
    "\n",
    "                        conformal_dict = {}\n",
    "                        for feat in suspect_features:\n",
    "                            feat = int(feat)\n",
    "                            dim = pcs_copula.shape[1]\n",
    "                            conf = conformal_class(\n",
    "                                conformity_score=\"sign\", input_dim=dim\n",
    "                            )\n",
    "                            conf.fit(\n",
    "                                x_train=pcs_copula, y_train=copula_samples[:, feat]\n",
    "                            )\n",
    "                            conformal_dict[feat] = conf.predict(\n",
    "                                x_test=pcs_test, y_test=test[:, feat]\n",
    "                            )\n",
    "                            logging.info(f\"Running analysis for feature = {feat}\")\n",
    "\n",
    "                        inliers_dict, outliers_dict = inlier_outlier_dicts(\n",
    "                            conformal_dict, suspect_features\n",
    "                        )\n",
    "\n",
    "                        feature = 0\n",
    "\n",
    "                        small_ci_ids, large_ci_ids, df_sorted = sort_cis_synth(\n",
    "                            conformal_dict, inliers_dict, suspect_features=[0]\n",
    "                        )\n",
    "\n",
    "                        df_conformal = conformal_dict[feature]\n",
    "\n",
    "                        inlier_ids = inliers_dict[feature]\n",
    "\n",
    "                        df_inlier = df_conformal.iloc[inlier_ids, :]\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # MSE EXPERIMENT - SECTION 4.2\n",
    "                        #\n",
    "                        ##############################################################\n",
    "\n",
    "                        inlier_ids = inliers_dict[0]\n",
    "                        outlier_ids = outliers_dict[0]\n",
    "\n",
    "                        # Create downstream linear model\n",
    "                        regr = linear_model.LinearRegression()\n",
    "\n",
    "                        # Train the model\n",
    "                        regr.fit(train[:, 0:-1], train[:, -1])\n",
    "\n",
    "                        # make predictions\n",
    "                        y_pred = regr.predict(train[:, 0:-1])\n",
    "\n",
    "                        # compute mean squared error\n",
    "                        mse = mean_squared_error(train[:, -1], y_pred)\n",
    "                        print(f\"MSE Train (CLEAN DATA): {mse} \\n\")\n",
    "                        wandb_dict[\"mse_train_clean\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "\n",
    "                        y_pred = regr.predict(test[:, 0:-1])\n",
    "                        mse = mean_squared_error(test[:, -1], y_pred)\n",
    "                        print(\n",
    "                            f\"MSE Test (UNKNOWN SAMPLES - INLIERS+OUTLIERS): {mse} \\n\"\n",
    "                        )\n",
    "                        wandb_dict[\"mse_test_unknown\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "\n",
    "                        y_pred = regr.predict(test[outlier_ids, 0:-1])\n",
    "                        mse = mean_squared_error(test[outlier_ids, -1], y_pred)\n",
    "                        print(f\"MSE Outliers: {mse} \\n\")\n",
    "                        wandb_dict[\"mse_test_outliers\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "\n",
    "                        y_pred = regr.predict(test[inlier_ids, 0:-1])\n",
    "                        mse = mean_squared_error(test[inlier_ids, -1], y_pred)\n",
    "                        print(f\"MSE Inliers: {mse } \\n\")\n",
    "                        wandb_dict[\"mse_test_inliers\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[small_ci_ids, 0:-1])\n",
    "                        mse = mean_squared_error(test[small_ci_ids, -1], y_pred)\n",
    "                        print(f\"MSE Inliers w/ SMALL CIs: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_inliers_small_ci\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[large_ci_ids, 0:-1])\n",
    "                        mse = mean_squared_error(test[large_ci_ids, -1], y_pred)\n",
    "                        print(f\"MSE Inliers w/  LARGE CIs: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_inliers_large_ci\"] = mse\n",
    "\n",
    "                        copula_noisy_ids = large_ci_ids\n",
    "                        copula_non_noisy_ids = small_ci_ids\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # MSE EXPERIMENT - SECTION 4.2 (COMPARISON METHODS)\n",
    "                        #\n",
    "                        ##############################################################\n",
    "\n",
    "                        logging.info(\"MSE EXPERIMENTS COMPARISON METHODS\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1:],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1:],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"mcd\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE MCD model - Small sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_mcd_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE MCD model - Large sigma {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_mcd_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 1:],\n",
    "                            y_train=train[:, 0],\n",
    "                            x_test=test[:, 1:],\n",
    "                            y_test=test[:, 0],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"mcd\",\n",
    "                        )\n",
    "\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE MCD Data - Small Sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_mcd_data_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE MCD Data - Large Sigma: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_mcd_data_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1:],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1:],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"ensemble\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE ENS model - Small sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_ens_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE ENS model - Large sigma {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_ens_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 1:],\n",
    "                            y_train=train[:, 0],\n",
    "                            x_test=test[:, 1:],\n",
    "                            y_test=test[:, 0],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"ensemble\",\n",
    "                        )\n",
    "\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE ENS Data - Small Sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_ens_data_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE ENS Data - Large Sigma: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_ens_data_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"conformal\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE Conformal Model Small CIs: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_conformal_small_ci\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE Conformal Model LARGE CIs: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_conformal_large_ci\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1:],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1:],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"gp\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE GP model - Small sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_gp_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE GP model - Large sigma {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_gp_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 1:],\n",
    "                            y_train=train[:, 0],\n",
    "                            x_test=test[:, 1:],\n",
    "                            y_test=test[:, 0],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"gp\",\n",
    "                        )\n",
    "\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE GP Data - Small Sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_gp_data_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE GP Data - Large Sigma: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_gp_data_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1:],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1:],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"qr\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE QR model - Small sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_qr_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE QR model - Large sigma {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_qr_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 1:],\n",
    "                            y_train=train[:, 0],\n",
    "                            x_test=test[:, 1:],\n",
    "                            y_test=test[:, 0],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"qr\",\n",
    "                        )\n",
    "\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE QR Data - Small Sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_qr_data_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE QR Data - Large Sigma: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_qr_data_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1:],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1:],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"bnn\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE BNN model - Small sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_bnn_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE BNN model - Large sigma {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_bnn_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 1:],\n",
    "                            y_train=train[:, 0],\n",
    "                            x_test=test[:, 1:],\n",
    "                            y_test=test[:, 0],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"bnn\",\n",
    "                        )\n",
    "                        bnn_noisy_ids = noisy\n",
    "                        bnn_non_noisy_ids = non_noisy\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE BNN Data - Small Sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_bnn_data_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE BNN Data - Large Sigma: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_bnn_data_large_sigma\"] = mse\n",
    "\n",
    "                        print(\"-------------------------------\")\n",
    "                        non_noisy, noisy = comparison_methods(\n",
    "                            x_train=train[:, 0:-1],\n",
    "                            y_train=train[:, -1:],\n",
    "                            x_test=test[:, 0:-1],\n",
    "                            y_test=test[:, -1:],\n",
    "                            inlier_ids=inlier_ids,\n",
    "                            df_inlier=df_inlier,\n",
    "                            model_type=\"copula\",\n",
    "                        )\n",
    "                        y_pred = regr.predict(test[non_noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[non_noisy, -1], y_pred)\n",
    "                        print(f\"MSE COPULA - Small Sigma: {mse}\\n \")\n",
    "                        wandb_dict[\"mse_test_copula_small_sigma\"] = mse\n",
    "\n",
    "                        y_pred = regr.predict(test[noisy, 0:-1])\n",
    "                        mse = mean_squared_error(test[noisy, -1], y_pred)\n",
    "                        print(f\"MSE COPULA - Large Sigma: {mse}\\n\")\n",
    "                        wandb_dict[\"mse_test_copula_large_sigma\"] = mse\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # METRICS EXPERIMENT - SECTION 4.1\n",
    "                        #\n",
    "                        ##############################################################\n",
    "\n",
    "                        ids = range(test.shape[0])\n",
    "\n",
    "                        ids = inlier_ids\n",
    "\n",
    "                        y_test_ids = noise_bool\n",
    "\n",
    "                        x_train_uncert, y_train_uncert = train[:, 1:], train[:, 0]\n",
    "                        x_test_uncert = test[:, 1:]\n",
    "\n",
    "                        df_conformal = conformal_dict[feature]\n",
    "\n",
    "                        dc = deepcopy(df_conformal)\n",
    "\n",
    "                        dc = dc.iloc[ids, :]\n",
    "\n",
    "                        dc[\"pred\"] = dc[\"min\"] + (dc[\"conf_interval\"] / 2)\n",
    "\n",
    "                        preds = dc[\"pred\"]  # target predictions\n",
    "                        # dc['true_val']  # ground truth observations\n",
    "                        true = orig_test[ids, 0]\n",
    "                        # lower bound of the prediction interval\n",
    "                        lb = dc[\"min\"]\n",
    "                        # upper bound of the prediction interval\n",
    "                        ub = dc[\"max\"]\n",
    "\n",
    "                        (\n",
    "                            uncert_metrics,\n",
    "                            excess,\n",
    "                            deficet,\n",
    "                            excess_all,\n",
    "                            deficet_all,\n",
    "                        ) = compute_uncertainty_metrics(\n",
    "                            preds=preds, lower_bound=lb, upper_bound=ub, true=true\n",
    "                        )\n",
    "\n",
    "                        idx_ordered = list(dc.sort_values(by=\"conf_interval\").index)\n",
    "                        results, roc = test_ood(np.array(y_test_ids)[ids], idx_ordered)\n",
    "\n",
    "                        wandb_dict = process_results(\n",
    "                            wandb_dict,\n",
    "                            results,\n",
    "                            roc,\n",
    "                            uncert_metrics,\n",
    "                            excess,\n",
    "                            deficet,\n",
    "                            excess_all,\n",
    "                            deficet_all,\n",
    "                            name=\"conformal_copula\",\n",
    "                        )\n",
    "\n",
    "                        from src.models.benchmarks import uncertainty_benchmark\n",
    "\n",
    "                        ##############################################################\n",
    "                        #\n",
    "                        # METRICS EXPERIMENT - SECTION 4.1 (COMPARISON METHODS)\n",
    "                        #\n",
    "                        ##############################################################\n",
    "\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"qr\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"bnn\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"gp\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"mcd\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"ensemble\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"conformal\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "                        uncertainty_benchmark(\n",
    "                            x_train=x_train_uncert,\n",
    "                            y_train=y_train_uncert,\n",
    "                            x_test=x_test_uncert,\n",
    "                            y_test=orig_test[:, 0],\n",
    "                            y_test_ids=y_test_ids,\n",
    "                            ids=ids,\n",
    "                            model_type=\"copula\",\n",
    "                            wandb_dict=wandb_dict,\n",
    "                            conformal_dict=None,\n",
    "                        )\n",
    "\n",
    "                        wandb.log(wandb_dict)\n",
    "                        run.finish()\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(traceback.format_exc())\n",
    "                        logging.info(e)\n",
    "                        wandb.log(wandb_dict)\n",
    "                        run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.7",
   "language": "python",
   "name": "venv3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
